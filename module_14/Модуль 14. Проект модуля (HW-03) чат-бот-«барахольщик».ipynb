{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "fdf1dc0e-b7ba-4752-9902-21a927c406b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import pickle\n",
    "import annoy\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1d5ce-72a3-4b4b-bcb2-684ceaf0771a",
   "metadata": {},
   "source": [
    "Продуктовые запросы берутся из \"ProductsDataset.csv\".  \n",
    "Непродуктовые -- из \"Болталки\" 8-го юнита."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddcc16d-a31d-4dfd-a2d5-c7392ab7449c",
   "metadata": {},
   "source": [
    "Загрузим необходимые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "341de640-6546-47fd-886f-51cdc7c70414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://clck.ru/3724V4 -O ProductsDataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "eb740c06-cd0e-477c-82f9-6a263ae35b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>product_id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Новые брюки на мальчика</td>\n",
       "      <td>Новые брюки на мальчика Новые льняные брюки ba...</td>\n",
       "      <td>5aaf758966fb077920118582</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9267</th>\n",
       "      <td>2 рубашки Henderson, Tatuum, Victor Alferi</td>\n",
       "      <td>2 рубашки Henderson, Tatuum, Victor Alferi 1) ...</td>\n",
       "      <td>5a59ed23d6775044877a2c5c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>Наклейки stick'n click для фотосессии</td>\n",
       "      <td>Наклейки stick'n click для фотосессии Цена за ...</td>\n",
       "      <td>59cc92a7a380b65c7b654b58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "225                      Новые брюки на мальчика   \n",
       "9267  2 рубашки Henderson, Tatuum, Victor Alferi   \n",
       "837        Наклейки stick'n click для фотосессии   \n",
       "\n",
       "                                                   text  \\\n",
       "225   Новые брюки на мальчика Новые льняные брюки ba...   \n",
       "9267  2 рубашки Henderson, Tatuum, Victor Alferi 1) ...   \n",
       "837   Наклейки stick'n click для фотосессии Цена за ...   \n",
       "\n",
       "                    product_id  labels  \n",
       "225   5aaf758966fb077920118582       1  \n",
       "9267  5a59ed23d6775044877a2c5c       1  \n",
       "837   59cc92a7a380b65c7b654b58       1  "
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Объединеним столбцы \"title\" и \"descrirption\". Также вставим столбец с обозначением продуктовых запросов [label=1]\n",
    "df_1 = pd.read_csv(\"ProductsDataset.csv\")\n",
    "df_1[\"title_descrirption\"] = df_1[\"title\"] + \" \" + df_1[\"descrirption\"]\n",
    "df_1 = df_1.rename(columns={\"title_descrirption\": \"text\"})\n",
    "df_1 = df_1[[\"title\", \"text\",\"product_id\"]]\n",
    "df_1[\"labels\"] = np.ones(len(df_1), dtype=int)\n",
    "# Удалим пропуски в наших данных\n",
    "df_1 = df_1.dropna()\n",
    "df_1.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "77e8dd8c-abab-49e4-8b1f-221b67795f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://clck.ru/3725rC -O QuestionsDataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "1990f822-8805-462a-8564-aa48abc2ce54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product_id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>Остап Сулейман Берта-Мария Бендер-бей.Как он о...</td>\n",
       "      <td>Живет себе в Рио.... \\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28473</th>\n",
       "      <td>Выгоден ли миру атеизм? .</td>\n",
       "      <td>Этот материальный мир - царство сатаны, а сата...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>Девушки, а вам бы понравилось если на члене у ...</td>\n",
       "      <td>Я Люблю на члене рисовать и писать всякие прик...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "2568   Остап Сулейман Берта-Мария Бендер-бей.Как он о...   \n",
       "28473                          Выгоден ли миру атеизм? .   \n",
       "4743   Девушки, а вам бы понравилось если на члене у ...   \n",
       "\n",
       "                                              product_id  labels  \n",
       "2568                             Живет себе в Рио.... \\n       0  \n",
       "28473  Этот материальный мир - царство сатаны, а сата...       0  \n",
       "4743   Я Люблю на члене рисовать и писать всякие прик...       0  "
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считаем файл с данными для болталки в кол-ве 36000 строк. И также вставим столбец с обозначением не продуктовые запросы [label=0]\n",
    "df_2 = pd.read_csv(\"QuestionsDataset.zip\", nrows=36000,).rename(columns={\"Вопрос\": \"text\", \"Ответ\": \"product_id\"})\n",
    "df_2[\"labels\"] = np.zeros(len(df_2), dtype=int)\n",
    "# Удалим пропуски в наших данных\n",
    "df_2 = df_2.dropna()\n",
    "df_2.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f9bd42-c0fe-42dc-9403-44386d71ac55",
   "metadata": {},
   "source": [
    "Осуществим препроцессинг текста (как минимум удаление знаков препинания, приведение к нижнему регистру, стемминг/лемматизация)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "df224700-8dec-4422-be6e-fefd86b76874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В данной функции будет осуществляться препроцессинг текста\n",
    "def preprocess_txt(line, morpher, sw, exclude):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "32dbc048-7d29-4fa1-a272-6fa16f8b3a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "c6427246-3004-457b-bafb-dfaa08dfa01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 33534/33534 [00:58<00:00, 569.80it/s]\n"
     ]
    }
   ],
   "source": [
    "df_1['Preprocessed_texts'] = df_1.progress_apply(lambda row: preprocess_txt(row['text'], morpher, sw, exclude), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "de404200-1d5e-4feb-a00b-83adbddc40d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 33534/33534 [00:07<00:00, 4650.24it/s]\n"
     ]
    }
   ],
   "source": [
    "df_1['title'] = df_1.progress_apply(lambda row: preprocess_txt(row['title'], morpher, sw, exclude), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "f864afd7-f26b-40f1-8117-ff82476f9691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 35999/35999 [01:05<00:00, 548.65it/s]\n"
     ]
    }
   ],
   "source": [
    "df_2['Preprocessed_texts'] = df_2.progress_apply(lambda row: preprocess_txt(row['text'], morpher, sw, exclude), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71be0ef5-1a19-4423-8c1d-7794f40c43ec",
   "metadata": {},
   "source": [
    "Перейдем к векторизации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "c5b0ffa2-490e-4899-b017-4fadfd942803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведем все предложения к одинаковой длине, задав её 100 \n",
    "# Максимальная длина предложения\n",
    "max_length = 100 # Укажите фиксированную длину\n",
    "df_1['padded_sentences'] = df_1['Preprocessed_texts'].apply(lambda x: x + [0] * (max_length - len(x)) if len(x) < max_length else x[:max_length])\n",
    "df_2['padded_sentences'] = df_2['Preprocessed_texts'].apply(lambda x: x + [0] * (max_length - len(x)) if len(x) < max_length else x[:max_length])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9f903-0dde-4214-af90-bf1ff39cebb2",
   "metadata": {},
   "source": [
    "Для подготовки данных для обучения классификатара, объедини продуктовые запросы и болталки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "b5f70a2f-d1d5-49ae-9eb0-09eeafd73f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединим два датафрэйма в один\n",
    "df = pd.concat([df_1, df_2], ignore_index=True)\n",
    "# Удалим пропуски в наших данных\n",
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "ba5799d7-551b-4652-8a87-2888ce8fc134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>product_id</th>\n",
       "      <th>labels</th>\n",
       "      <th>Preprocessed_texts</th>\n",
       "      <th>padded_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[юбка, детский, orby]</td>\n",
       "      <td>Юбка детская ORBY Новая, не носили ни разу. В ...</td>\n",
       "      <td>58e3cfe6132ca50e053f5f82</td>\n",
       "      <td>1</td>\n",
       "      <td>[юбка, детский, orby, новый, носить, реал, кра...</td>\n",
       "      <td>[юбка, детский, orby, новый, носить, реал, кра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ботильон]</td>\n",
       "      <td>Ботильоны Новые,привезены из Чехии ,указан раз...</td>\n",
       "      <td>5667531b2b7f8d127d838c34</td>\n",
       "      <td>1</td>\n",
       "      <td>[ботильон, новыепривезти, чехия, указать, разм...</td>\n",
       "      <td>[ботильон, новыепривезти, чехия, указать, разм...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[брюки]</td>\n",
       "      <td>Брюки Размер 40-42. Брюки почти новые - не зна...</td>\n",
       "      <td>59534826aaab284cba337e06</td>\n",
       "      <td>1</td>\n",
       "      <td>[брюки, размер, 4042, брюки, новый, знать, мер...</td>\n",
       "      <td>[брюки, размер, 4042, брюки, новый, знать, мер...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                               text  \\\n",
       "0  [юбка, детский, orby]  Юбка детская ORBY Новая, не носили ни разу. В ...   \n",
       "1             [ботильон]  Ботильоны Новые,привезены из Чехии ,указан раз...   \n",
       "2                [брюки]  Брюки Размер 40-42. Брюки почти новые - не зна...   \n",
       "\n",
       "                 product_id  labels  \\\n",
       "0  58e3cfe6132ca50e053f5f82       1   \n",
       "1  5667531b2b7f8d127d838c34       1   \n",
       "2  59534826aaab284cba337e06       1   \n",
       "\n",
       "                                  Preprocessed_texts  \\\n",
       "0  [юбка, детский, orby, новый, носить, реал, кра...   \n",
       "1  [ботильон, новыепривезти, чехия, указать, разм...   \n",
       "2  [брюки, размер, 4042, брюки, новый, знать, мер...   \n",
       "\n",
       "                                    padded_sentences  \n",
       "0  [юбка, детский, orby, новый, носить, реал, кра...  \n",
       "1  [ботильон, новыепривезти, чехия, указать, разм...  \n",
       "2  [брюки, размер, 4042, брюки, новый, знать, мер...  "
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "08d1e48e-74c0-4b06-a794-05c9d4481811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим модель Word2Vec на полученных данных\n",
    "model =  Word2Vec(df['padded_sentences'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "model_prod = Word2Vec(df_1['title'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "model_mail = Word2Vec(df_2['padded_sentences'], vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "1467d7bb-9468-4927-a975-670537521d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраненим векторизаванные модели\n",
    "model.save(\"word2vec.model\")\n",
    "model_prod.save(\"word2vec_prod.model\")\n",
    "model_mail.save(\"word2vec_mail.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "f8e8469b-e616-443c-abfa-42ece24feafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Векторизация слов\n",
    "def vectorize_sentence(sentence):\n",
    "    vectorized_words = [model.wv[word] for word in sentence if word in model.wv.key_to_index]\n",
    "    if len(vectorized_words) > 0:\n",
    "        return np.mean(vectorized_words, axis=0).astype(np.float64)\n",
    "    else:\n",
    "        return np.zeros((100,), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "f0911efc-7f08-4a58-86db-515a0cdead99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 69533/69533 [00:05<00:00, 11968.61it/s]\n"
     ]
    }
   ],
   "source": [
    "df['vectorized_sentences'] = df['padded_sentences'].progress_apply(vectorize_sentence)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "dbf7ab34-5a89-413f-91c0-b530bfc4f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания для векторизованных предложений\n",
    "X = np.vstack(df['vectorized_sentences'].values)\n",
    "y = np.array(df['labels']) # Метки классов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111a5bf0-cd38-4981-9a00-503bdeb1c397",
   "metadata": {},
   "source": [
    "Разделем выборку на обучающую и валидационную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "14d780cb-01d6-41bb-932c-a640287102d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение набора данных на обучающий и тестовый\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "719684d2-f136-4916-8987-ed04e7b76f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55626, 100), (55626,))"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим на размер тренировочных данных\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "36cb7bf1-fc32-4fc6-bf7a-15a599725000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13907, 100), (13907,))"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим на размер тестовых данных\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11474738-659c-4be6-9488-a0e8bc1f0482",
   "metadata": {},
   "source": [
    "Обучим классификатор с расчётом метрик на валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "1edab812-f79c-4a6d-941b-989e587732af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearLR, Vectors:  0.958078665420292\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели логистической регрессии\n",
    "lg_model = LogisticRegression(random_state=42, max_iter=500)\n",
    "lg_model.fit(X_train, y_train)\n",
    "\n",
    "# Оценка производительности модели\n",
    "accuracy = lg_model.score(X_test, y_test)\n",
    "print(\"LinearLR, Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cbe352-2772-44f8-a1f5-c7026a4fa77c",
   "metadata": {},
   "source": [
    "Сохраним обученную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "b41eb8a3-5878-4879-b2a5-abd4f899291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение обученной модели\n",
    "with open('trained_logistic_regression_model.pkl', 'wb') as file:\n",
    "    pickle.dump(lg_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a8a993-6cf4-4e8f-8fec-6dfab66f0181",
   "metadata": {},
   "source": [
    "#### Реализация поиска похожих товаров в контентной части бота"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6252ff-a270-4ae8-a105-aa8724bae82d",
   "metadata": {},
   "source": [
    "Этот код является определением функции `get_answer`. Он принимает три аргумента: `question` (строка), `model_lg` (объект LogisticRegression) со значением по умолчанию `model`, и `word2vec` (объект Word2Vec) со значением по умолчанию `Word2Vec`. Функция возвращает строку.\n",
    "\n",
    "Таким образом, этот код определяет функцию `get_answer` с определенными типами аргументов и возвращаемого значения, и значениями по умолчанию для `model_lg` и `word2vec`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35be91f-6458-41f7-bfd0-f855b5b51e06",
   "metadata": {},
   "source": [
    "* Все названия товаров свёрнем в векторное представление Word2Vec (на предобученном исходном датасете).\n",
    "* Построен индекс по названиям документов.\n",
    "* Для товарных запросов реализован поиск в индексе (запрос также оборачивается Word2Vec, происходит проход в индекс)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "0ff73de3-dfd6-42c1-bd1b-f127a3a0ac89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33534it [00:01, 22591.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Данная фунция сворачивает все продуктовые запросы в векторное представление\n",
    "index_prod = annoy.AnnoyIndex(100 ,'angular')\n",
    "df_prod = df_1[['title', 'product_id']]\n",
    "index_map_products = {}\n",
    "counter = 0\n",
    "\n",
    "for index_, row in tqdm(df_prod.iterrows()): \n",
    "    n_w2v = 0\n",
    "    index_map_products[counter] = row.iloc[1]\n",
    "    question = row.iloc[0]\n",
    "    vector = np.zeros(100)\n",
    "    for word in question:\n",
    "        if word in model_prod.wv:\n",
    "            vector += model_prod.wv[word]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector = vector / n_w2v\n",
    "    index_prod.add_item(counter, vector)\n",
    "            \n",
    "    counter += 1\n",
    "    \n",
    "index_prod.build(10)\n",
    "index_prod.save('products_.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "19161f4b-03f6-484b-98f9-039f4b774891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35999it [00:02, 16227.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Данная фунция сворачивает все запросы из болталки в векторное представление\n",
    "index_mail = annoy.AnnoyIndex(100 ,'angular')\n",
    "df_mail = df_2[['Preprocessed_texts', 'product_id']]\n",
    "index_map_mail = {}\n",
    "counter = 0\n",
    "\n",
    "for index_, row in tqdm(df_mail.iterrows()): \n",
    "    n_w2v = 0\n",
    "    index_map_mail[counter] = row.iloc[1]\n",
    "    question = row.iloc[0]\n",
    "    vector = np.zeros(100)\n",
    "    for word in question:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector = vector / n_w2v\n",
    "    index_mail.add_item(counter, vector)\n",
    "            \n",
    "    counter += 1\n",
    "\n",
    "index_mail.build(10)\n",
    "index_mail.save('mail_.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "5811b9fd-005e-46e3-a9fb-bfd5fc1d760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция выдает на запрошенный предобработанный вопрос готовый ответ\n",
    "def find_answer(question, model, index, index_map):\n",
    "    # preprocessed_question = preprocess_txt(question)\n",
    "    n_w2v = 0\n",
    "    vector = np.zeros(100)\n",
    "    for word in question:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector = vector / n_w2v\n",
    "    if model == model_prod:\n",
    "        answer_index = index.get_nns_by_vector(vector, 1, search_k=-2)\n",
    "        # print('прод=',answer_index)\n",
    "    else: \n",
    "        answer_index = index_mail.get_nns_by_vector(vector, 1, search_k=-1)     \n",
    "        # print('не прод=',answer_index)\n",
    "    return index_map[answer_index[0]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "f39646e7-c451-49f0-b2b0-e1ee399b774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция определяет вид запроса (продуктовый или нет) и запрашивает и функции find_answer ответ на преодработанные вопрос\n",
    "def get_answer(question: str, model_lg: LogisticRegression = lg_model, word2vec: Word2Vec = Word2Vec) -> str:\n",
    "    \n",
    "    '''\n",
    "    Определяет вид запроса (продуктовый или нет) и находит ответ,\n",
    "    для продуктового запроса - product_id продукта, для непродутового - текст.\n",
    "    '''\n",
    "    morpher = MorphAnalyzer()\n",
    "    sw = set(get_stop_words(\"ru\"))\n",
    "    exclude = set(string.punctuation)\n",
    "    preprocess_text = preprocess_txt(question, morpher, sw, exclude)\n",
    "    vector = vectorize_sentence(preprocess_text)\n",
    "    # print(vector)\n",
    "    # Преобразуем список векторизованных предложений в массив NumPy\n",
    "    # vector = np.stack(vectorize_question)\n",
    "\n",
    "    if lg_model.predict(vector.reshape(1, -1))[0] == 1:\n",
    "        # print(\"Продуковый запрос\")\n",
    "        return find_answer(preprocess_text, model_prod, index_prod, index_map_products)\n",
    "    else:\n",
    "        # print(\"Не продуктовый запрос\")\n",
    "        return find_answer(preprocess_text, model_mail, index_mail, index_map_mail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "014ad9fa-59e9-4f3b-a53a-5c1f2d0ccd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим обученной модель предсказания вопроса: продутовый или нет\n",
    "with open('trained_logistic_regression_model.pkl', 'rb') as file:\n",
    "    lg_model= pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "881c6479-0ddc-4703-b6f3-167defcbcc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ на продуктовый запрос,  58e3cfe6132ca50e053f5f82\n",
      "Ответ на болталку,  Рекомендации для всех-Тигр – символ года, животное серьезное, и четко определяет цветовую гамму новогодних нарядов – это его любимые цвета тигровых оттенков – оранжевые, золотистые, желтые. В одежде желательно иметь что-то полосатое. <br> <br>Не забудьте про украшения - аксессуары и украшения рекомендуется подобрать из натуральных материалов, камней. Хороши металлические кольца, бусы, браслеты, серьги из золота, серебра, меди и платины (но не более двух различных металлов) . Прекрасно подойдут бижутерия и украшения из ювелирных сплавов, например цепочки . Для одежды можно использовать украшения из кожи, меха, хлопка и др. Обратите внимание и на вашу обувь: металлический Тигр очень обидится, если вы будете встречать его 2010 год в обыкновенных домашних тапочках. Не бывать этому. Женщинам нужны кожаные туфли, мужчинам – ботинки, желательно с каким-нибудь броским декоративным элементом, например, с блестящей металлической пряжкой. <br><br>И, конечно, по традиции Новый год нужно встречать в чем-то новом, чтобы оставить в уходящем году все напасти и неприятности. <br><br>. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ответ на продуктовый запрос, \",get_answer(\"Юбка детская ORBY\"))\n",
    "print(\"Ответ на болталку, \", get_answer(\"Где ключи от танка\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
